{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('San Francisco', 0, 13, 'GPE')]\n",
      "['San', 'B', 'GPE']\n",
      "['Francisco', 'I', 'GPE']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"San Francisco considers banning sidewalk delivery robots\")\n",
    "\n",
    "# document level\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print(ents)\n",
    "\n",
    "# token level\n",
    "ent_san = [doc[0].text, doc[0].ent_iob_, doc[0].ent_type_]\n",
    "ent_francisco = [doc[1].text, doc[1].ent_iob_, doc[1].ent_type_]\n",
    "print(ent_san)  # ['San', 'B', 'GPE']\n",
    "print(ent_francisco)  # ['Francisco', 'I', 'GPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before []\n",
      "After [('fb', 0, 1, 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"fb is hiring a new vice president of global policy\")\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('Before', ents)\n",
    "# The model didn't recognize \"fb\" as an entity :(\n",
    "\n",
    "# Create a span for the new entity\n",
    "fb_ent = Span(doc, 0, 1, label=\"ORG\")\n",
    "orig_ents = list(doc.ents)\n",
    "\n",
    "# Option 1: Modify the provided entity spans, leaving the rest unmodified\n",
    "doc.set_ents([fb_ent], default=\"unmodified\")\n",
    "\n",
    "# Option 2: Assign a complete list of ents to doc.ents\n",
    "doc.ents = orig_ents + [fb_ent]\n",
    "\n",
    "ents = [(e.text, e.start, e.end, e.label_) for e in doc.ents]\n",
    "print('After', ents)\n",
    "# [('fb', 0, 1, 'ORG')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_ent = doc.char_span(0, 2, label=\"ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ()\n",
      "After (London,)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import spacy\n",
    "from spacy.attrs import ENT_IOB, ENT_TYPE\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp.make_doc(\"London is a big city in the United Kingdom.\")\n",
    "print(\"Before\", doc.ents)  # []\n",
    "\n",
    "header = [ENT_IOB, ENT_TYPE]\n",
    "attr_array = numpy.zeros((len(doc), len(header)), dtype=\"uint64\")\n",
    "attr_array[0, 0] = 3  # B\n",
    "attr_array[0, 1] = doc.vocab.strings[\"GPE\"]\n",
    "doc.from_array(header, attr_array)\n",
    "print(\"After\", doc.ents)  # [London]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ruhi Sharma\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on web development at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"When Ruhi Sharma started working on web development at Google in 2007, few people outside of the company took him seriously.\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x2a578f94d50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'tutorial',\n",
       " 'is',\n",
       " 'about',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'in',\n",
       " 'spaCy',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introduction_doc = nlp(\n",
    "...     \"This tutorial is about Natural Language Processing in spaCy.\"\n",
    "... )\n",
    "type(introduction_doc)\n",
    "spacy.tokens.doc.Doc\n",
    "\n",
    "[token.text for token in introduction_doc]\n",
    "['This', 'tutorial', 'is', 'about', 'Natural', 'Language',\n",
    "'Processing', 'in', 'spaCy', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"C:/path_to_your_file/introduction.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../folder_name/introduction.txt\"  # One directory up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Microsoft VS Code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # This will show the current working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File introduction.txt does not exist.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_name = \"introduction.txt\"\n",
    "file_path = Path(file_name)\n",
    "\n",
    "if file_path.exists():\n",
    "    introduction_doc = nlp(file_path.read_text(encoding=\"utf-8\"))\n",
    "    print([token.text for token in introduction_doc])\n",
    "else:\n",
    "    print(f\"File {file_name} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Gus Proto is a Python...\n",
      "He is interested in learning...\n"
     ]
    }
   ],
   "source": [
    "# Sample text\n",
    "about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    ")\n",
    "\n",
    "# Processing the text with spaCy\n",
    "about_doc = nlp(about_text)\n",
    "\n",
    "# Extracting sentences\n",
    "sentences = list(about_doc.sents)\n",
    "\n",
    "# Checking the number of sentences\n",
    "print(len(sentences))>>> ellipsis_text = (\n",
    "...     \"Gus, can you, ... never mind, I forgot\"\n",
    "...     \" what I was saying. So, do you think\"\n",
    "...     \" we should ...\"\n",
    "... )\n",
    "\n",
    "from spacy.language import Language\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "... def set_custom_boundaries(doc):\n",
    "...     \"\"\"Add support to use `...` as a delimiter for sentence detection\"\"\"\n",
    "...     for token in doc[:-1]:\n",
    "...         if token.text == \"...\":\n",
    "...             doc[token.i + 1].is_sent_start = True\n",
    "...     return doc\n",
    "...\n",
    "\n",
    "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
    "custom_nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n",
    "custom_ellipsis_doc = custom_nlp(ellipsis_text)\n",
    "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
    "for sentence in custom_ellipsis_sentences:\n",
    "...     print(sentence)\n",
    "...\n",
    "Gus, can you, ...\n",
    "never mind, I forgot what I was saying.\n",
    "So, do you think we should ...\n",
    "\n",
    "# Printing the first 5 tokens of each sentence\n",
    "for sentence in sentences:\n",
    "    print(f\"{sentence[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Gus Proto is a Python...\n",
      "He is interested in learning...\n"
     ]
    }
   ],
   "source": [
    "# Multi-line string without using ellipses or commas incorrectly\n",
    "about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    ")\n",
    "\n",
    "# Process text using spaCy\n",
    "about_doc = nlp(about_text)\n",
    "\n",
    "# Get sentences\n",
    "sentences = list(about_doc.sents)\n",
    "\n",
    "# Check the number of sentences\n",
    "print(len(sentences))\n",
    "\n",
    "# Print first 5 tokens of each sentence\n",
    "for sentence in sentences:\n",
    "    print(f\"{sentence[:5]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text with Whitespace  '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{'Text with Whitespace':<22}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with Whitespace  \n"
     ]
    }
   ],
   "source": [
    "# Align the text within 22 characters\n",
    "formatted_text = f\"{'Text with Whitespace':<22}\"\n",
    "print(formatted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'a', 'London@based', 'Fintech', 'company', '.', 'He']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['for', 'a', 'London@based', 'Fintech', 'company', '.', 'He']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_about_text = (\n",
    "...     \"Gus Proto is a Python developer currently\"\n",
    "...     \" working for a London@based Fintech\"\n",
    "...     \" company. He is interested in learning\"\n",
    "...     \" Natural Language Processing.\"\n",
    "... )\n",
    "\n",
    "print([token.text for token in nlp(custom_about_text)[8:15]])\n",
    "['for', 'a', 'London@based', 'Fintech', 'company', '.', 'He']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ent.text = 'Abacuss Academy'\n",
      "ent.start_char = 0\n",
      "ent.end_char = 15\n",
      "ent.label_ = 'PERSON'\n",
      "spacy.explain('PERSON') = People, including fictional\n",
      "\n",
      "ent.text = 'USA'\n",
      "ent.start_char = 31\n",
      "ent.end_char = 34\n",
      "ent.label_ = 'GPE'\n",
      "spacy.explain('GPE') = Countries, cities, states\n",
      "\n",
      "ent.text = 'the City of America'\n",
      "ent.start_char = 38\n",
      "ent.end_char = 57\n",
      "ent.label_ = 'GPE'\n",
      "spacy.explain('GPE') = Countries, cities, states\n",
      "\n",
      "ent.text = 'Abacuss'\n",
      "ent.start_char = 78\n",
      "ent.end_char = 85\n",
      "ent.label_ = 'PERSON'\n",
      "spacy.explain('PERSON') = People, including fictional\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Input text about the piano academy\n",
    "piano_class_text = (\n",
    "    \"Abacuss Academy is situated\"\n",
    "    \" in USA or the City of America and has\"\n",
    "    \" world-class Abacuss instructors.\"\n",
    ")\n",
    "\n",
    "# Process the text with spaCy to extract named entities\n",
    "Abacuss_class_doc = nlp(piano_class_text)\n",
    "\n",
    "# Loop through detected entities and print details\n",
    "for ent in Abacuss_class_doc.ents:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "ent.text = '{ent.text}'\n",
    "ent.start_char = {ent.start_char}\n",
    "ent.end_char = {ent.end_char}\n",
    "ent.label_ = '{ent.label_}'\n",
    "spacy.explain('{ent.label_}') = {spacy.explain(ent.label_)}\"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Abacuss Academy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is situated in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    USA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " or \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the City of America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and has world-class \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Abacuss\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " instructors.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "displacy.serve(Abacuss_class_doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 5 people surveyed, [REDACTED] , [REDACTED] and [REDACTED] like apples. [REDACTED] and [REDACTED] like oranges.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Input text for the survey\n",
    "survey_text = (\n",
    "    \"Out of 5 people surveyed, James Robert,\"\n",
    "    \" Julie Fuller and Benjamin Brooks like\"\n",
    "    \" apples. Kelly Cox and Matthew Evans\"\n",
    "    \" like oranges.\"\n",
    ")\n",
    "\n",
    "# Function to replace person names with \"[REDACTED]\"\n",
    "def replace_person_names(token):\n",
    "    if token.ent_iob != 0 and token.ent_type_ == \"PERSON\":\n",
    "        return \"[REDACTED] \"\n",
    "    return token.text_with_ws\n",
    "\n",
    "# Function to redact names\n",
    "def redact_names(nlp_doc):\n",
    "    with nlp_doc.retokenize() as retokenizer:\n",
    "        for ent in nlp_doc.ents:\n",
    "            retokenizer.merge(ent)\n",
    "    tokens = map(replace_person_names, nlp_doc)\n",
    "    return \"\".join(tokens)\n",
    "\n",
    "# Process the text\n",
    "survey_doc = nlp(survey_text)\n",
    "\n",
    "# Redact names and print the result\n",
    "print(redact_names(survey_doc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
